To test the effectiveness of these rules, you can perform the following steps:

1. **Trigger Response Test**: Create queries that match the triggers specified in the rules section and verify if the AI provides the correct response as outlined.

2. **Documentation Adherence Test**: Submit queries related to documentation and check if the AI follows the general and section-specific guidelines.

3. **Technical Compliance Test**: Provide coding-related queries and observe if the AI adheres to the technical guidelines, such as using TypeScript, avoiding classes, and following DRY principles.

4. **Code Implementation Test**: Test the AI's ability to follow code implementation guidelines by asking for code examples or modifications and checking for adherence to best practices.

5. **Error Handling Test**: Present scenarios that require error handling and validation to see if the AI uses early returns, custom error types, and validation libraries as specified.

6. **UI and Styling Test**: Request UI-related advice or code and verify if the AI uses modern UI frameworks and responsive design patterns.

7. **State Management Test**: Ask about state management strategies and check if the AI suggests modern solutions like Zustand or React Query.

8. **Security and Performance Test**: Pose questions about security and performance optimizations to see if the AI provides guidance aligned with the guidelines.

9. **Testing and Documentation Test**: Inquire about testing strategies and documentation practices to ensure the AI recommends unit tests, clear comments, and thorough documentation.

10. **Iterative Refinement Test**: Provide complex queries and observe if the AI uses iterative refinement to optimize responses before finalizing.
 